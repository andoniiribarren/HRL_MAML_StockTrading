{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d915aa32",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d686209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc9d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (45900, 8)\n"
     ]
    }
   ],
   "source": [
    "from finHRL.preprocess.preprocessor import YahooDownloader\n",
    "\n",
    "with open(\"../finHRL/preprocess/tickers/ticker_lists.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dow_30 = data[\"DOW_30\"]\n",
    "cryptos = data[\"CRYPTO_7\"]\n",
    "\n",
    "TRAIN_START_DATE = '2017-01-01'\n",
    "TRAIN_END_DATE = '2022-01-01'\n",
    "TEST_START_DATE = '2022-01-01'\n",
    "TEST_END_DATE = '2023-01-01'\n",
    "\n",
    "\n",
    "\n",
    "df = YahooDownloader(start_date = pd.to_datetime(TRAIN_START_DATE) - datetime.timedelta(days=30),\n",
    "                     end_date = TEST_END_DATE,\n",
    "                     ticker_list = dow_30).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b6be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "INDICATORS = ['macd',\n",
    "              'rsi_30',\n",
    "              'cci_30']\n",
    "\n",
    "from finHRL.preprocess.preprocessor import FeatureEngineer\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)\n",
    "processed = processed.copy()\n",
    "processed = processed.fillna(0)\n",
    "processed = processed.replace(np.inf,0)\n",
    "\n",
    "processed = processed[processed.date >= TRAIN_START_DATE].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed.tic.unique())\n",
    "print(stock_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c7441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = processed[processed.date < TEST_START_DATE]\n",
    "df_test = processed[processed.date >= TEST_START_DATE]\n",
    "\n",
    "\n",
    "df_train[\"dayorder\"] = df_train[\"date\"].astype(\"category\").cat.codes\n",
    "df_test[\"dayorder\"] = df_test[\"date\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca4d0d",
   "metadata": {},
   "source": [
    "# Base RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e43b69",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev.hyperparameter_searching.base_RL_hs import hyperparams_opt_RL\n",
    "\n",
    "hs_opt = hyperparams_opt_RL(\n",
    "    df_train=df_train,\n",
    "    df_test=df_test,\n",
    "    indicators=INDICATORS,\n",
    "    n_episodes_train=10,\n",
    "    n_trials=80\n",
    ")\n",
    "\n",
    "hs_opt.run_opt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0624f1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575caf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 800      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -10.9    |\n",
      "|    learning_rate      | 4.33e-05 |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 2.41     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0163   |\n",
      "------------------------------------\n",
      "day: 1258, episode: 1\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1873833.71\n",
      "total_reward: 873833.71\n",
      "total_cost: 234241.71\n",
      "total_trades: 35094\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.26e+03 |\n",
      "|    ep_rew_mean        | 0.628    |\n",
      "| time/                 |          |\n",
      "|    fps                | 86       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1600     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -614     |\n",
      "|    learning_rate      | 4.33e-05 |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -2.89    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     31\u001b[39m best_hiperparams = {\u001b[33m'\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.9460266042874034\u001b[39m,\n\u001b[32m     32\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mmax_grad_norm\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.5723516016378004\u001b[39m,\n\u001b[32m     33\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mn_steps\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m8\u001b[39m,\n\u001b[32m     34\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m4.3336870145809356e-05\u001b[39m,\n\u001b[32m     35\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33ment_coef\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m7.323986049778401e-08\u001b[39m}\n\u001b[32m     37\u001b[39m model = agent.get_model(\u001b[33m\"\u001b[39m\u001b[33ma2c\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m                         learning_rate = best_hiperparams[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     39\u001b[39m                         gamma = best_hiperparams[\u001b[33m'\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m                         ent_coef = best_hiperparams[\u001b[33m'\u001b[39m\u001b[33ment_coef\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     43\u001b[39m                         verbose=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m trained_model = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma2c_best_hp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m*\u001b[49m\u001b[43mepisode_len\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/finHRL/agent/models.py:52\u001b[39m, in \u001b[36mbaseRLAgent.train_model\u001b[39m\u001b[34m(model, tb_log_name, total_timesteps, callbacks)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(\n\u001b[32m     47\u001b[39m     model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     callbacks: \u001b[38;5;28mtype\u001b[39m[BaseCallback] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     51\u001b[39m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCallbackList\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/stable_baselines3/a2c/a2c.py:201\u001b[39m, in \u001b[36mA2C.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    193\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[32m    194\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    199\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    200\u001b[39m ) -> SelfA2C:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_timesteps < total_timesteps:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     continue_training = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[39m, in \u001b[36mOnPolicyAlgorithm.collect_rollouts\u001b[39m\u001b[34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[39m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[32m    216\u001b[39m         clipped_actions = np.clip(actions, \u001b[38;5;28mself\u001b[39m.action_space.low, \u001b[38;5;28mself\u001b[39m.action_space.high)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m new_obs, rewards, dones, infos = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28mself\u001b[39m.num_timesteps += env.num_envs\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[39m, in \u001b[36mVecEnv.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[33;03mStep the environments with the given action\u001b[39;00m\n\u001b[32m    201\u001b[39m \n\u001b[32m    202\u001b[39m \u001b[33;03m:param actions: the action\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;28mself\u001b[39m.step_async(actions)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[39m, in \u001b[36mDummyVecEnv.step_wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> VecEnvStepReturn:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_envs):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         obs, \u001b[38;5;28mself\u001b[39m.buf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m.buf_infos[env_idx] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mself\u001b[39m.buf_dones[env_idx] = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/stable_baselines3/common/monitor.py:94\u001b[39m, in \u001b[36mMonitor.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.needs_reset:\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTried to step environment that needs reset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.rewards.append(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/finHRL/env_stocktrading/trading_env_RL.py:324\u001b[39m, in \u001b[36mStockTradingEnv.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m    318\u001b[39m end_total_asset = \u001b[38;5;28mself\u001b[39m.state[\u001b[32m0\u001b[39m] + \u001b[38;5;28msum\u001b[39m(\n\u001b[32m    319\u001b[39m     np.array(\u001b[38;5;28mself\u001b[39m.state[\u001b[32m1\u001b[39m : (\u001b[38;5;28mself\u001b[39m.stock_dim + \u001b[32m1\u001b[39m)])\n\u001b[32m    320\u001b[39m     * np.array(\u001b[38;5;28mself\u001b[39m.state[(\u001b[38;5;28mself\u001b[39m.stock_dim + \u001b[32m1\u001b[39m) : (\u001b[38;5;28mself\u001b[39m.stock_dim * \u001b[32m2\u001b[39m + \u001b[32m1\u001b[39m)])\n\u001b[32m    321\u001b[39m )\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m.asset_memory.append(end_total_asset)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28mself\u001b[39m.date_memory.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# UPDATED self.reward = end_total_asset - begin_total_asset\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;28mself\u001b[39m.reward = np.log(end_total_asset / begin_total_asset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/finHRL/env_stocktrading/trading_env_RL.py:461\u001b[39m, in \u001b[36mStockTradingEnv._get_date\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_date\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtic\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) > \u001b[32m1\u001b[39m:\n\u001b[32m    462\u001b[39m         date = \u001b[38;5;28mself\u001b[39m.data.date.unique()[\u001b[32m0\u001b[39m]\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/pandas/core/series.py:2419\u001b[39m, in \u001b[36mSeries.unique\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2356\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[32m   2357\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2358\u001b[39m \u001b[33;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[32m   2359\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2417\u001b[39m \u001b[33;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[32m   2418\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/pandas/core/base.py:1029\u001b[39m, in \u001b[36mIndexOpsMixin.unique\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1027\u001b[39m     result = values.unique()\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m     result = \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/pandas/core/algorithms.py:401\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munique\u001b[39m(values):\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[32m    310\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    399\u001b[39m \u001b[33;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/pandas/core/algorithms.py:441\u001b[39m, in \u001b[36munique_with_mask\u001b[39m\u001b[34m(values, mask)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    440\u001b[39m     uniques = table.unique(values)\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     uniques = \u001b[43m_reconstruct_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/pandas/core/algorithms.py:200\u001b[39m, in \u001b[36m_reconstruct_data\u001b[39m\u001b[34m(values, dtype, original)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reconstruct_data\u001b[39m(\n\u001b[32m    185\u001b[39m     values: ArrayLike, dtype: DtypeObj, original: AnyArrayLike\n\u001b[32m    186\u001b[39m ) -> ArrayLike:\n\u001b[32m    187\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m    reverse of _ensure_data\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m \u001b[33;03m    ExtensionArray or np.ndarray\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCExtensionArray\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m values.dtype == dtype:\n\u001b[32m    201\u001b[39m         \u001b[38;5;66;03m# Catch DatetimeArray/TimedeltaArray\u001b[39;00m\n\u001b[32m    202\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype):\n\u001b[32m    205\u001b[39m         \u001b[38;5;66;03m# i.e. ExtensionDtype; note we have ruled out above the possibility\u001b[39;00m\n\u001b[32m    206\u001b[39m         \u001b[38;5;66;03m#  that values.dtype == dtype\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TFM/repoTFM/HRLMAMLforST/hrlmamlenv/lib/python3.12/site-packages/pandas/core/dtypes/generic.py:42\u001b[39m, in \u001b[36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[39m\u001b[34m(cls, inst)\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[33m\"\u001b[39m\u001b[33m_typ\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_subclasscheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Raise instead of returning False\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# TRAINING with BEST HPs\n",
    "from finHRL.env_stocktrading.trading_env_RL import StockTradingEnv\n",
    "from finHRL.agent.models import baseRLAgent\n",
    "\n",
    "# state_space_noHRL = [balance, close prices_i, stock_shares_i, MACD_i, rsi30_i, cci30_i, turbulences_i]\n",
    "episode_len = df_train.dayorder.nunique()\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension \n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "tr_env = StockTradingEnv(\n",
    "    df = df_train,\n",
    "    stock_dim=stock_dimension,\n",
    "    hmax= 100,\n",
    "    initial_amount=1000000,\n",
    "    num_stock_shares=num_stock_shares,\n",
    "    buy_cost_pct=buy_cost_list,\n",
    "    sell_cost_pct=sell_cost_list,\n",
    "    state_space= state_space,\n",
    "    action_space= stock_dimension,\n",
    "    tech_indicator_list=INDICATORS,\n",
    "    make_plots=True,\n",
    "    print_verbosity=2\n",
    ")\n",
    "\n",
    "agent = baseRLAgent(env=tr_env)\n",
    "\n",
    "n_episodes = 50\n",
    "\n",
    "best_hiperparams = {'gamma': 0.9460266042874034,\n",
    "                    'max_grad_norm': 0.5723516016378004,\n",
    "                    'n_steps': 8,\n",
    "                    'learning_rate': 4.3336870145809356e-05,\n",
    "                    'ent_coef': 7.323986049778401e-08}\n",
    "\n",
    "model = agent.get_model(\"a2c\",\n",
    "                        learning_rate = best_hiperparams['learning_rate'],\n",
    "                        gamma = best_hiperparams['gamma'],\n",
    "                        max_grad_norm = best_hiperparams['max_grad_norm'],\n",
    "                        n_steps = best_hiperparams['n_steps'],\n",
    "                        ent_coef = best_hiperparams['ent_coef'],\n",
    "                        verbose=1)\n",
    "\n",
    "\n",
    "trained_model = agent.train_model(\n",
    "    model,\n",
    "    tb_log_name=\"a2c_best_hp\",\n",
    "    total_timesteps= n_episodes*episode_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8473e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction...\n",
      "day: 250, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1037854.17\n",
      "total_reward: 37854.17\n",
      "total_cost: 1383.70\n",
      "total_trades: 3489\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "test_env = StockTradingEnv(\n",
    "    df = df_test,\n",
    "    stock_dim=stock_dimension,\n",
    "    hmax= 100,\n",
    "    initial_amount=1000000,\n",
    "    num_stock_shares=num_stock_shares,\n",
    "    buy_cost_pct=buy_cost_list,\n",
    "    sell_cost_pct=sell_cost_list,\n",
    "    state_space= state_space,\n",
    "    action_space= stock_dimension,\n",
    "    tech_indicator_list=INDICATORS,\n",
    "    make_plots=False,\n",
    "    print_verbosity=1\n",
    ")\n",
    "\n",
    "df_account_value_a2c, df_actions_a2c = baseRLAgent.predict_RL(\n",
    "    model=trained_model, \n",
    "    environment = test_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111fcf7",
   "metadata": {},
   "source": [
    "# HRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a65d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finHRL.env_stocktrading.trading_env_HRL import StockTradingEnvHRL\n",
    "\n",
    "# state_space_manager = [close prices_i, MACD_i, rsi30_i, cci30_i] Quizas quitar algún indicador\n",
    "\n",
    "# state_space_worker = [balance, close_prices_i, stock_shares_i, manager_actions_i]                 # QUizás añadir agún indicador de riesgo a estudiar y hacer pruebas\n",
    "\n",
    "\n",
    "\n",
    "# state_space_noHRL = [balance, close prices_i, stock_shares_i, MACD_i, rsi30_i, cci30_i]\n",
    "\n",
    "\n",
    "# action_space_manager = {-1, 0, 1} * 30\n",
    "# action_space_manager = {0,1} * 30 (para calcular cuántas, multiplicar por hmax)\n",
    "\n",
    "episode_len = processed.dayorder.nunique()\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "\n",
    "state_space_manager = (len(INDICATORS) + 1)*stock_dimension\n",
    "state_space_worker = (1 + 3*stock_dimension)\n",
    "\n",
    "\n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "\n",
    "tr_env = StockTradingEnvHRL(\n",
    "    df = processed,\n",
    "    stock_dim=stock_dimension,\n",
    "    hmax= 100,\n",
    "    initial_amount=1000000,\n",
    "    num_stock_shares=num_stock_shares,\n",
    "    buy_cost_pct=buy_cost_list,\n",
    "    sell_cost_pct=sell_cost_list,\n",
    "    state_space= state_space,\n",
    "    action_space= stock_dimension,\n",
    "    tech_indicator_list=INDICATORS,\n",
    "    make_plots=True,\n",
    "    print_verbosity=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530709f6",
   "metadata": {},
   "source": [
    "# Pendiente\n",
    "\n",
    "- LR está en 0.0003: Probar a bajar a 5e-5 o 1e-5\n",
    "- Incluir train -> Test etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrlmamlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
